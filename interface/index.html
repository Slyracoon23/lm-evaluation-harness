
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="A framework for evaluating language models">
      
      
      
        <link rel="canonical" href="https://github.com/EleutherAI/lm-evaluation-harness/interface/">
      
      
        <link rel="prev" href="../model_guide/">
      
      
        <link rel="next" href="../new_task_guide/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.9">
    
    
      
        <title>Interface - LM Evaluation Harness</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.4af4bdda.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#user-guide" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="LM Evaluation Harness" class="md-header__button md-logo" aria-label="LM Evaluation Harness" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            LM Evaluation Harness
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Interface
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6m0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4M7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/EleutherAI/lm-evaluation-harness" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    EleutherAI/lm-evaluation-harness
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="LM Evaluation Harness" class="md-nav__button md-logo" aria-label="LM Evaluation Harness" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    LM Evaluation Harness
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/EleutherAI/lm-evaluation-harness" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    EleutherAI/lm-evaluation-harness
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Documentation
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Documentation
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../API_guide/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API Guide
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../model_guide/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model Guide
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Interface
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Interface
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#command-line-interface" class="md-nav__link">
    <span class="md-ellipsis">
      Command-line Interface
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#external-library-usage" class="md-nav__link">
    <span class="md-ellipsis">
      External Library Usage
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../new_task_guide/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    New Task Guide
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../task_guide/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Task Guide
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../decontamination/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Decontamination
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chat-template-readme/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Chat Templates
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../CONTRIBUTING/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Contributing
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    API Reference
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            API Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_1" >
        
          
          <label class="md-nav__link" for="__nav_4_1" id="__nav_4_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Models
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1">
            <span class="md-nav__icon md-icon"></span>
            Models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/api_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/hf_vlms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    HF VLMs
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#command-line-interface" class="md-nav__link">
    <span class="md-ellipsis">
      Command-line Interface
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#external-library-usage" class="md-nav__link">
    <span class="md-ellipsis">
      External Library Usage
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="user-guide">User Guide<a class="headerlink" href="#user-guide" title="Permanent link">&para;</a></h1>
<p>This document details the interface exposed by <code>lm-eval</code> and provides details on what flags are available to users.</p>
<h2 id="command-line-interface">Command-line Interface<a class="headerlink" href="#command-line-interface" title="Permanent link">&para;</a></h2>
<p>A majority of users run the library by cloning it from Github, installing the package as editable, and running the <code>python -m lm_eval</code> script.</p>
<p>Equivalently, running the library can be done via the <code>lm-eval</code> entrypoint at the command line.</p>
<p>This mode supports a number of command-line arguments, the details of which can also be seen via running with <code>-h</code> or <code>--help</code>:</p>
<ul>
<li>
<p><code>--model</code> : Selects which model type or provider is evaluated. Must be a string corresponding to the name of the model type/provider being used. See <a href="https://github.com/EleutherAI/lm-evaluation-harness/tree/main#model-apis-and-inference-servers">the main README</a> for a full list of enabled model names and supported libraries or APIs.</p>
</li>
<li>
<p><code>--model_args</code> : Controls parameters passed to the model constructor. Accepts a string containing comma-separated keyword arguments to the model class of the format <code>"arg1=val1,arg2=val2,..."</code>, such as, for example <code>--model_args pretrained=EleutherAI/pythia-160m,dtype=float32</code>. For a full list of what keyword arguments, see the initialization of the <code>lm_eval.api.model.LM</code> subclass, e.g. <a href="https://github.com/EleutherAI/lm-evaluation-harness/blob/365fcda9b85bbb6e0572d91976b8daf409164500/lm_eval/models/huggingface.py#L66"><code>HFLM</code></a></p>
</li>
<li>
<p><code>--tasks</code> : Determines which tasks or task groups are evaluated. Accepts a comma-separated list of task names or task group names. Must be solely comprised of valid tasks/groups. A list of supported tasks can be viewed with <code>--tasks list</code>.</p>
</li>
<li>
<p><code>--num_fewshot</code> : Sets the number of few-shot examples to place in context. Must be an integer.</p>
</li>
<li>
<p><code>--gen_kwargs</code> : takes an arg string in same format as <code>--model_args</code> and creates a dictionary of keyword arguments. These will be passed to the models for all called <code>generate_until</code> (free-form or greedy generation task) tasks, to set options such as the sampling temperature or <code>top_p</code> / <code>top_k</code>. For a list of what args are supported for each model type, reference the respective library's documentation (for example, the documentation for <code>transformers.AutoModelForCausalLM.generate()</code>.) These kwargs will be applied to all <code>generate_until</code> tasks called--we do not currently support unique gen_kwargs or batch_size values per task in a single run of the library. To control these on a per-task level, set them in that task's YAML file.</p>
</li>
<li>
<p><code>--batch_size</code> : Sets the batch size used for evaluation. Can be a positive integer or <code>"auto"</code> to automatically select the largest batch size that will fit in memory, speeding up evaluation. One can pass <code>--batch_size auto:N</code> to re-select the maximum batch size <code>N</code> times during evaluation. This can help accelerate evaluation further, since <code>lm-eval</code> sorts documents in descending order of context length.</p>
</li>
<li>
<p><code>--max_batch_size</code> : Sets the maximum batch size to try to fit in memory, if <code>--batch_size auto</code> is passed.</p>
</li>
<li>
<p><code>--device</code> : Sets which device to place the model onto. Must be a string, for example, <code>"cuda", "cuda:0", "cpu", "mps"</code>. Defaults to "cuda", and can be ignored if running multi-GPU or running a non-local model type.</p>
</li>
<li>
<p><code>--output_path</code> : A string of the form <code>dir/file.jsonl</code> or <code>dir/</code>. Provides a path where high-level results will be saved, either into the file named or into the directory named. If <code>--log_samples</code> is passed as well, then per-document outputs and metrics will be saved into the directory as well.</p>
</li>
<li>
<p><code>--log_samples</code> : If this flag is passed, then the model's outputs, and the text fed into the model, will be saved at per-document granularity. Must be used with <code>--output_path</code>.</p>
</li>
<li>
<p><code>--limit</code> : Accepts an integer, or a float between 0.0 and 1.0 . If passed, will limit the number of documents to evaluate to the first X documents (if an integer) per task or first X% of documents per task. Useful for debugging, especially on costly API models.</p>
</li>
<li>
<p><code>--use_cache</code> : Should be a path where a sqlite db file can be written to. Takes a string of format <code>/path/to/sqlite_cache_</code> in order to create a cache db at <code>/path/to/sqlite_cache_rank{i}.db</code> for each process (0-NUM_GPUS). This allows results of prior runs to be cached, so that there is no need to re-run results in order to re-score or re-run a given (model, task) pair again.</p>
</li>
<li>
<p><code>--cache_requests</code> : Can be "true", "refresh", or "delete". "true" means that the cache should be used. "refresh" means that you wish to regenerate the cache, which you should run if you change your dataset configuration for a given task. "delete" will delete the cache. Cached files are stored under lm_eval/cache/.cache unless you specify a different path via the environment variable: <code>LM_HARNESS_CACHE_PATH</code>. e.g. <code>LM_HARNESS_CACHE_PATH=~/Documents/cache_for_lm_harness</code>.</p>
</li>
<li>
<p><code>--check_integrity</code> : If this flag is used, the library tests for each task selected are run to confirm task integrity.</p>
</li>
<li>
<p><code>--write_out</code> : Used for diagnostic purposes to observe the format of task documents passed to a model. If this flag is used, then prints the prompt and gold target string for the first document of each task.</p>
</li>
<li>
<p><code>--show_config</code> : If used, prints the full <code>lm_eval.api.task.TaskConfig</code> contents (non-default settings the task YAML file) for each task which was run, at the completion of an evaluation. Useful for when one is modifying a task's configuration YAML locally to transmit the exact configurations used for debugging or for reproducibility purposes.</p>
</li>
<li>
<p><code>--include_path</code> : Accepts a path to a folder. If passed, then all YAML files containing <code>lm-eval</code> compatible task configurations will be added to the task registry as available tasks. Used for when one is writing config files for their own task in a folder other than <code>lm_eval/tasks/</code>.</p>
</li>
<li>
<p><code>--system_instruction</code>: Specifies a system instruction string to prepend to the prompt.</p>
</li>
<li>
<p><code>--apply_chat_template</code> : This flag specifies whether to apply a chat template to the prompt. It can be used in the following ways:</p>
</li>
<li><code>--apply_chat_template</code> : When used without an argument, applies the only available chat template to the prompt. For Hugging Face models, if no dedicated chat template exists, the default chat template will be applied.</li>
<li>
<p><code>--apply_chat_template template_name</code> : If the model has multiple chat templates, apply the specified template to the prompt.</p>
<p>For Hugging Face models, the default chat template can be found in the <a href="https://github.com/huggingface/transformers/blob/fc35907f95459d7a6c5281dfadd680b6f7b620e3/src/transformers/tokenization_utils_base.py#L1912"><code>default_chat_template</code></a> property of the Transformers Tokenizer.</p>
</li>
<li>
<p><code>--fewshot_as_multiturn</code> : If this flag is on, the Fewshot examples are treated as a multi-turn conversation. Questions are provided as user content and answers are provided as assistant responses. Requires <code>--num_fewshot</code> to be set to be greater than 0, and <code>--apply_chat_template</code> to be on.</p>
</li>
<li>
<p><code>--predict_only</code>: Generates the model outputs without computing metrics. Use with <code>--log_samples</code> to retrieve decoded results.</p>
</li>
<li>
<p><code>--seed</code>: Set seed for python's random, numpy and torch.  Accepts a comma-separated list of 3 values for python's random, numpy, and torch seeds, respectively, or a single integer to set the same seed for all three.  The values are either an integer or 'None' to not set the seed. Default is <code>0,1234,1234</code> (for backward compatibility).  E.g. <code>--seed 0,None,8</code> sets <code>random.seed(0)</code> and <code>torch.manual_seed(8)</code>. Here numpy's seed is not set since the second value is <code>None</code>.  E.g, <code>--seed 42</code> sets all three seeds to 42.</p>
</li>
<li>
<p><code>--wandb_args</code>:  Tracks logging to Weights and Biases for evaluation runs and includes args passed to <code>wandb.init</code>, such as <code>project</code> and <code>job_type</code>. Full list <a href="https://docs.wandb.ai/ref/python/init">here</a>. e.g., <code>--wandb_args project=test-project,name=test-run</code>. Also allows for the passing of the step to log things at (passed to <code>wandb.run.log</code>), e.g., <code>--wandb_args step=123</code>.</p>
</li>
<li>
<p><code>--hf_hub_log_args</code> : Logs evaluation results to Hugging Face Hub. Accepts a string with the arguments separated by commas. Available arguments:</p>
</li>
<li><code>hub_results_org</code> - organization name on Hugging Face Hub, e.g., <code>EleutherAI</code>. If not provided, the results will be pushed to the owner of the Hugging Face token,</li>
<li><code>hub_repo_name</code> - repository name on Hugging Face Hub (deprecated, <code>details_repo_name</code> and <code>results_repo_name</code> should be used instead), e.g., <code>lm-eval-results</code>,</li>
<li><code>details_repo_name</code> - repository name on Hugging Face Hub to store details, e.g., <code>lm-eval-results</code>,</li>
<li><code>results_repo_name</code> - repository name on Hugging Face Hub to store results, e.g., <code>lm-eval-results</code>,</li>
<li><code>push_results_to_hub</code> - whether to push results to Hugging Face Hub, can be <code>True</code> or <code>False</code>,</li>
<li><code>push_samples_to_hub</code> - whether to push samples results to Hugging Face Hub, can be <code>True</code> or <code>False</code>. Requires <code>--log_samples</code> to be set,</li>
<li><code>public_repo</code> - whether the repository is public, can be <code>True</code> or <code>False</code>,</li>
<li><code>leaderboard_url</code> - URL to the leaderboard, e.g., <code>https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard</code>.</li>
<li><code>point_of_contact</code> - Point of contact for the results dataset, e.g., <code>yourname@example.com</code>.</li>
<li>
<p><code>gated</code> - whether to gate the details dataset, can be <code>True</code> or <code>False</code>.</p>
</li>
<li>
<p><code>--metadata</code>: JSON string to pass to TaskConfig. Used for some tasks which require additional metadata to be passed for processing. E.g., <code>--metadata '{"key": "value"}'</code>.</p>
</li>
</ul>
<h2 id="external-library-usage">External Library Usage<a class="headerlink" href="#external-library-usage" title="Permanent link">&para;</a></h2>
<p>We also support using the library's external API for use within model training loops or other scripts.</p>
<p><code>lm_eval</code> supplies two functions for external import and use: <code>lm_eval.evaluate()</code> and <code>lm_eval.simple_evaluate()</code>.</p>
<p><code>simple_evaluate()</code> can be used by simply creating an <code>lm_eval.api.model.LM</code> subclass that implements the methods described in the <a href="https://github.com/EleutherAI/lm-evaluation-harness/tree/main/docs/model_guide.md">Model Guide</a>, and wrapping your custom model in that class as follows:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">lm_eval</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">lm_eval.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">setup_logging</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="o">...</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="c1"># initialize logging</span>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="n">setup_logging</span><span class="p">(</span><span class="s2">&quot;DEBUG&quot;</span><span class="p">)</span> <span class="c1"># optional, but recommended; or you can set up logging yourself</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="n">my_model</span> <span class="o">=</span> <span class="n">initialize_my_model</span><span class="p">()</span> <span class="c1"># create your model (could be running finetuning with some custom modeling code)</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="o">...</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="c1"># instantiate an LM subclass that takes your initialized model and can run</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="c1"># - `Your_LM.loglikelihood()`</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span class="c1"># - `Your_LM.loglikelihood_rolling()`</span>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a><span class="c1"># - `Your_LM.generate_until()`</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a><span class="n">lm_obj</span> <span class="o">=</span> <span class="n">Your_LM</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">my_model</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a><span class="c1"># indexes all tasks from the `lm_eval/tasks` subdirectory.</span>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a><span class="c1"># Alternatively, you can set `TaskManager(include_path=&quot;path/to/my/custom/task/configs&quot;)`</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a><span class="c1"># to include a set of tasks in a separate directory.</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a><span class="n">task_manager</span> <span class="o">=</span> <span class="n">lm_eval</span><span class="o">.</span><span class="n">tasks</span><span class="o">.</span><span class="n">TaskManager</span><span class="p">()</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a><span class="c1"># Setting `task_manager` to the one above is optional and should generally be done</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a><span class="c1"># if you want to include tasks from paths other than ones in `lm_eval/tasks`.</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a><span class="c1"># `simple_evaluate` will instantiate its own task_manager if it is set to None here.</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a><span class="n">results</span> <span class="o">=</span> <span class="n">lm_eval</span><span class="o">.</span><span class="n">simple_evaluate</span><span class="p">(</span> <span class="c1"># call simple_evaluate</span>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>    <span class="n">model</span><span class="o">=</span><span class="n">lm_obj</span><span class="p">,</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>    <span class="n">tasks</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;taskname1&quot;</span><span class="p">,</span> <span class="s2">&quot;taskname2&quot;</span><span class="p">],</span>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>    <span class="n">num_fewshot</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a>    <span class="n">task_manager</span><span class="o">=</span><span class="n">task_manager</span><span class="p">,</span>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a>    <span class="o">...</span>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a><span class="p">)</span>
</code></pre></div>
<p>See the <code>simple_evaluate()</code> and <code>evaluate()</code> functions in <a href="../lm_eval/evaluator.py#:~:text=simple_evaluate">lm_eval/evaluator.py</a> for a full description of all arguments available. All keyword arguments to simple_evaluate share the same role as the command-line flags described previously.</p>
<p>Additionally, the <code>evaluate()</code> function offers the core evaluation functionality provided by the library, but without some of the special handling and simplification + abstraction provided by <code>simple_evaluate()</code>.</p>
<p>As a brief example usage of <code>evaluate()</code>:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">lm_eval</span>
<a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>
<a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="c1"># suppose you&#39;ve defined a custom lm_eval.api.Task subclass in your own external codebase</span>
<a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a><span class="kn">from</span><span class="w"> </span><span class="nn">my_tasks</span><span class="w"> </span><span class="kn">import</span> <span class="n">MyTask1</span>
<a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a><span class="o">...</span>
<a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a>
<a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a><span class="c1"># create your model (could be running finetuning with some custom modeling code)</span>
<a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a><span class="n">my_model</span> <span class="o">=</span> <span class="n">initialize_my_model</span><span class="p">()</span>
<a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a><span class="o">...</span>
<a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a>
<a id="__codelineno-1-11" name="__codelineno-1-11" href="#__codelineno-1-11"></a><span class="c1"># instantiate an LM subclass that takes your initialized model and can run</span>
<a id="__codelineno-1-12" name="__codelineno-1-12" href="#__codelineno-1-12"></a><span class="c1"># - `Your_LM.loglikelihood()`</span>
<a id="__codelineno-1-13" name="__codelineno-1-13" href="#__codelineno-1-13"></a><span class="c1"># - `Your_LM.loglikelihood_rolling()`</span>
<a id="__codelineno-1-14" name="__codelineno-1-14" href="#__codelineno-1-14"></a><span class="c1"># - `Your_LM.generate_until()`</span>
<a id="__codelineno-1-15" name="__codelineno-1-15" href="#__codelineno-1-15"></a><span class="n">lm_obj</span> <span class="o">=</span> <span class="n">Your_LM</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">my_model</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<a id="__codelineno-1-16" name="__codelineno-1-16" href="#__codelineno-1-16"></a>
<a id="__codelineno-1-17" name="__codelineno-1-17" href="#__codelineno-1-17"></a><span class="c1"># optional: the task_manager indexes tasks including ones</span>
<a id="__codelineno-1-18" name="__codelineno-1-18" href="#__codelineno-1-18"></a><span class="c1"># specified by the user through `include_path`.</span>
<a id="__codelineno-1-19" name="__codelineno-1-19" href="#__codelineno-1-19"></a><span class="n">task_manager</span> <span class="o">=</span> <span class="n">lm_eval</span><span class="o">.</span><span class="n">tasks</span><span class="o">.</span><span class="n">TaskManager</span><span class="p">(</span>
<a id="__codelineno-1-20" name="__codelineno-1-20" href="#__codelineno-1-20"></a>    <span class="n">include_path</span><span class="o">=</span><span class="s2">&quot;/path/to/custom/yaml&quot;</span>
<a id="__codelineno-1-21" name="__codelineno-1-21" href="#__codelineno-1-21"></a>    <span class="p">)</span>
<a id="__codelineno-1-22" name="__codelineno-1-22" href="#__codelineno-1-22"></a>
<a id="__codelineno-1-23" name="__codelineno-1-23" href="#__codelineno-1-23"></a><span class="c1"># To get a task dict for `evaluate`</span>
<a id="__codelineno-1-24" name="__codelineno-1-24" href="#__codelineno-1-24"></a><span class="n">task_dict</span> <span class="o">=</span> <span class="n">lm_eval</span><span class="o">.</span><span class="n">tasks</span><span class="o">.</span><span class="n">get_task_dict</span><span class="p">(</span>
<a id="__codelineno-1-25" name="__codelineno-1-25" href="#__codelineno-1-25"></a>    <span class="p">[</span>
<a id="__codelineno-1-26" name="__codelineno-1-26" href="#__codelineno-1-26"></a>        <span class="s2">&quot;mmlu&quot;</span><span class="p">,</span> <span class="c1"># A stock task</span>
<a id="__codelineno-1-27" name="__codelineno-1-27" href="#__codelineno-1-27"></a>        <span class="s2">&quot;my_custom_task&quot;</span><span class="p">,</span> <span class="c1"># A custom task</span>
<a id="__codelineno-1-28" name="__codelineno-1-28" href="#__codelineno-1-28"></a>        <span class="p">{</span>
<a id="__codelineno-1-29" name="__codelineno-1-29" href="#__codelineno-1-29"></a>            <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span> <span class="c1"># A dict that configures a task</span>
<a id="__codelineno-1-30" name="__codelineno-1-30" href="#__codelineno-1-30"></a>            <span class="s2">&quot;doc_to_text&quot;</span><span class="p">:</span> <span class="o">...</span><span class="p">,</span>
<a id="__codelineno-1-31" name="__codelineno-1-31" href="#__codelineno-1-31"></a>            <span class="p">},</span>
<a id="__codelineno-1-32" name="__codelineno-1-32" href="#__codelineno-1-32"></a>        <span class="n">MyTask1</span> <span class="c1"># A task object from `lm_eval.task.Task`</span>
<a id="__codelineno-1-33" name="__codelineno-1-33" href="#__codelineno-1-33"></a>        <span class="p">],</span>
<a id="__codelineno-1-34" name="__codelineno-1-34" href="#__codelineno-1-34"></a>    <span class="n">task_manager</span> <span class="c1"># A task manager that allows lm_eval to</span>
<a id="__codelineno-1-35" name="__codelineno-1-35" href="#__codelineno-1-35"></a>                 <span class="c1"># load the task during evaluation.</span>
<a id="__codelineno-1-36" name="__codelineno-1-36" href="#__codelineno-1-36"></a>                 <span class="c1"># If none is provided, `get_task_dict`</span>
<a id="__codelineno-1-37" name="__codelineno-1-37" href="#__codelineno-1-37"></a>                 <span class="c1"># will instantiate one itself, but this</span>
<a id="__codelineno-1-38" name="__codelineno-1-38" href="#__codelineno-1-38"></a>                 <span class="c1"># only includes the stock tasks so users</span>
<a id="__codelineno-1-39" name="__codelineno-1-39" href="#__codelineno-1-39"></a>                 <span class="c1"># will need to set this if including</span>
<a id="__codelineno-1-40" name="__codelineno-1-40" href="#__codelineno-1-40"></a>                 <span class="c1"># custom paths is required.</span>
<a id="__codelineno-1-41" name="__codelineno-1-41" href="#__codelineno-1-41"></a>    <span class="p">)</span>
<a id="__codelineno-1-42" name="__codelineno-1-42" href="#__codelineno-1-42"></a>
<a id="__codelineno-1-43" name="__codelineno-1-43" href="#__codelineno-1-43"></a><span class="n">results</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span>
<a id="__codelineno-1-44" name="__codelineno-1-44" href="#__codelineno-1-44"></a>    <span class="n">lm</span><span class="o">=</span><span class="n">lm_obj</span><span class="p">,</span>
<a id="__codelineno-1-45" name="__codelineno-1-45" href="#__codelineno-1-45"></a>    <span class="n">task_dict</span><span class="o">=</span><span class="n">task_dict</span><span class="p">,</span>
<a id="__codelineno-1-46" name="__codelineno-1-46" href="#__codelineno-1-46"></a>    <span class="o">...</span>
<a id="__codelineno-1-47" name="__codelineno-1-47" href="#__codelineno-1-47"></a><span class="p">)</span>
</code></pre></div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.instant", "navigation.tracking", "navigation.expand", "navigation.indexes", "navigation.top", "search.highlight", "search.share", "content.code.copy"], "search": "../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.c8b220af.min.js"></script>
      
    
  </body>
</html>